{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71135f8b-5bc3-4bc0-8355-f863ac12494c",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unterminated string literal (detected at line 64) (2471013656.py, line 64)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 64\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mdata=load_dataset(\"students_dataset.csv)\u001b[39m\n                      ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m unterminated string literal (detected at line 64)\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "from collections import counter\n",
    "import pprint\n",
    "import csv\n",
    "def load_dataset(filename):\n",
    "    data=[]\n",
    "    with open(filename,newline='') as csvfile:\n",
    "        for row in reader:\n",
    "            row[\"CGPA\"]=float(row[\"CGPA\"])\n",
    "            data.append(row)\n",
    "    return data\n",
    "def discretize_cgpa(cgpa):\n",
    "    if cgpa>=7.5:\n",
    "        return \"High\"\n",
    "    elif cgpa>=6:\n",
    "        return \"Medium\"\n",
    "    else :\n",
    "        return \"Low\"\n",
    "def entropy(data_subset):\n",
    "    labels=[record[\"JobOffer\"] for record in data_subset]\n",
    "    total=len(labels)\n",
    "    counts=counter(labels)\n",
    "    ent=0.0\n",
    "    for count in counts.values():\n",
    "        p=count/total\n",
    "        ent-=p*math.log2(p)\n",
    "    return ent\n",
    "def info_gain(data_subset,attribute):\n",
    "    total_entropy=entropy(data_subste)\n",
    "    value=set(record[atribute] for record in data_subste)\n",
    "    for val in values:\n",
    "        subset=[record for record in data_subset if record[attribute]==val]\n",
    "        weighted_entropy+=(len(subset)/total)* entropy(subset)\n",
    "    return total_entropy-weighted_entropy\n",
    "def id3(data_subset,attributes):\n",
    "    labels=[record[\"JobOffer\"] for record in data_subset]\n",
    "    if len(set(labels))==1:\n",
    "        return labels[0]\n",
    "    if not attributes:\n",
    "        return majority_class(data_subset)\n",
    "    gains=[(attr,info_gain(data_subset,attr)) for attr in attributes]                                                                                                                                     \n",
    "    best_attr,best_gain=max(gains,key=lambda x: x[1]\n",
    "                            if best_gain==0:\n",
    "                                return majority_class(data_subset)\n",
    "    tree={best_attr:{}}\n",
    "    values=set(record[best_attr] for record in data_subset)\n",
    "    for val in values:\n",
    "        subset=[record for record in data_subste if record[best_attr]==val]\n",
    "        if not subset:\n",
    "            tree[best_attr][va]=majority_class(data_subset)\n",
    "        else:\n",
    "            tree[best_attr][val]=id3(subset,remaining_attrs)\n",
    "    return true\n",
    "def predict(tree,sample,default_class=None):\n",
    "    if not instance(tree,dict):\n",
    "        return tree\n",
    "    attribute=nextr(iter(tree))\n",
    "    value=sample.get(attribute)\n",
    "    if value in tree[attribute]:\n",
    "        return predcit (tree[attribute][value],sample,default_class)\n",
    "    else:\n",
    "        return default_class\n",
    "if __name__==\"__main__\":\n",
    "    data=load_dataset(\"students_dataset.csv)\n",
    "    for record in data:\n",
    "                      record[\"CGPA\"]=discretize_cgpa(record[\"CGPA\"])\n",
    "    attributes=[\"CGPA\",\"Interactive\",\"Practical\",\"Communication\"]\n",
    "    decision_tree=id3(data,attributes)\n",
    "    print(\"Decision Tree:\")\n",
    "    pprint.pprint(decision_tree)\n",
    "    new_sample={\n",
    "        \"CGPA\":discretize_cgpa(7.0),\"Interactive\":\"Yes\",\"Practical\":\"Good\",\"Communication\":\"Moderate\"\n",
    "    }\n",
    "    prediction=predict(decision_tree,new_sample,default_class=majority_class(data))\n",
    "    print(f\"\\nPredicted Job Offer for {new_sample}:{prediction}\"}\n",
    "          \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "379fb9e2-07d7-4bb3-a2fb-827b92127800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree:\n",
      "{'Interactive': {'No': 'No', 'Yes': 'Yes'}}\n",
      "\n",
      "Predicted Job Offer for {'CGPA': 'Medium', 'Interactive': 'Yes', 'Practical': 'Good', 'Communication': 'Moderate'}: Yes\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "from collections import Counter\n",
    "import pprint\n",
    "import csv\n",
    "\n",
    "def load_dataset(filename):\n",
    "    data = []\n",
    "    with open(filename, newline='') as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        for row in reader:\n",
    "            row[\"CGPA\"] = float(row[\"CGPA\"])\n",
    "            data.append(row)\n",
    "    return data\n",
    "\n",
    "def discretize_cgpa(cgpa):\n",
    "    if cgpa >= 7.5:\n",
    "        return \"High\"\n",
    "    elif cgpa >= 6:\n",
    "        return \"Medium\"\n",
    "    else:\n",
    "        return \"Low\"\n",
    "\n",
    "def entropy(data_subset):\n",
    "    labels = [record[\"JobOffer\"] for record in data_subset]\n",
    "    total = len(labels)\n",
    "    counts = Counter(labels)\n",
    "    ent = 0.0\n",
    "    for count in counts.values():\n",
    "        p = count / total\n",
    "        ent -= p * math.log2(p)\n",
    "    return ent\n",
    "\n",
    "def info_gain(data_subset, attribute):\n",
    "    total_entropy = entropy(data_subset)\n",
    "    values = set(record[attribute] for record in data_subset)\n",
    "    weighted_entropy = 0.0\n",
    "    total = len(data_subset)\n",
    "\n",
    "    for val in values:\n",
    "        subset = [record for record in data_subset if record[attribute] == val]\n",
    "        weighted_entropy += (len(subset) / total) * entropy(subset)\n",
    "\n",
    "    return total_entropy - weighted_entropy\n",
    "\n",
    "def majority_class(data_subset):\n",
    "    labels = [record[\"JobOffer\"] for record in data_subset]\n",
    "    return Counter(labels).most_common(1)[0][0]\n",
    "\n",
    "def id3(data_subset, attributes):\n",
    "    labels = [record[\"JobOffer\"] for record in data_subset]\n",
    "\n",
    "    # If all labels are the same → return that label\n",
    "    if len(set(labels)) == 1:\n",
    "        return labels[0]\n",
    "\n",
    "    # If no attributes left → return majority class\n",
    "    if not attributes:\n",
    "        return majority_class(data_subset)\n",
    "\n",
    "    # Select best attribute\n",
    "    gains = [(attr, info_gain(data_subset, attr)) for attr in attributes]\n",
    "    best_attr, best_gain = max(gains, key=lambda x: x[1])\n",
    "\n",
    "    if best_gain == 0:\n",
    "        return majority_class(data_subset)\n",
    "\n",
    "    tree = {best_attr: {}}\n",
    "    values = set(record[best_attr] for record in data_subset)\n",
    "\n",
    "    for val in values:\n",
    "        subset = [record for record in data_subset if record[best_attr] == val]\n",
    "        if not subset:\n",
    "            tree[best_attr][val] = majority_class(data_subset)\n",
    "        else:\n",
    "            remaining_attrs = [attr for attr in attributes if attr != best_attr]\n",
    "            tree[best_attr][val] = id3(subset, remaining_attrs)\n",
    "\n",
    "    return tree\n",
    "\n",
    "def predict(tree, sample, default_class=None):\n",
    "    if not isinstance(tree, dict):\n",
    "        return tree\n",
    "\n",
    "    attribute = next(iter(tree))\n",
    "    value = sample.get(attribute)\n",
    "\n",
    "    if value in tree[attribute]:\n",
    "        return predict(tree[attribute][value], sample, default_class)\n",
    "    else:\n",
    "        return default_class\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    data = load_dataset(\"stu_dataset.csv\")\n",
    "\n",
    "    # Discretize CGPA values\n",
    "    for record in data:\n",
    "        record[\"CGPA\"] = discretize_cgpa(record[\"CGPA\"])\n",
    "\n",
    "    attributes = [\"CGPA\", \"Interactive\", \"Practical\", \"Communication\"]\n",
    "\n",
    "    decision_tree = id3(data, attributes)\n",
    "    print(\"Decision Tree:\")\n",
    "    pprint.pprint(decision_tree)\n",
    "\n",
    "    new_sample = {\n",
    "        \"CGPA\": discretize_cgpa(7.0),\n",
    "        \"Interactive\": \"Yes\",\n",
    "        \"Practical\": \"Good\",\n",
    "        \"Communication\": \"Moderate\"\n",
    "    }\n",
    "\n",
    "    prediction = predict(decision_tree, new_sample, default_class=majority_class(data))\n",
    "    print(f\"\\nPredicted Job Offer for {new_sample}: {prediction}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e283a48-a43a-46ed-9e93-9fe582467ffd",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '>=9'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 134\u001b[39m\n\u001b[32m    131\u001b[39m \u001b[38;5;66;03m# ---------- Example run ----------\u001b[39;00m\n\u001b[32m    133\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m134\u001b[39m     data = \u001b[43mload_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mjob_data.csv\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    136\u001b[39m     \u001b[38;5;66;03m# discretize CGPA\u001b[39;00m\n\u001b[32m    137\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m record \u001b[38;5;129;01min\u001b[39;00m data:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 13\u001b[39m, in \u001b[36mload_dataset\u001b[39m\u001b[34m(filename)\u001b[39m\n\u001b[32m     11\u001b[39m     reader = csv.DictReader(csvfile)\n\u001b[32m     12\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m reader:\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m         row[\u001b[33m\"\u001b[39m\u001b[33mCGPA\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mCGPA\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m         data.append(row)\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "\u001b[31mValueError\u001b[39m: could not convert string to float: '>=9'"
     ]
    }
   ],
   "source": [
    "import math\n",
    "from collections import Counter, deque\n",
    "import csv\n",
    "import pprint\n",
    "\n",
    "# ---------- Helper functions ----------\n",
    "\n",
    "def load_dataset(filename):\n",
    "    data = []\n",
    "    with open(filename, newline=\"\") as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        for row in reader:\n",
    "            row[\"CGPA\"] = float(row[\"CGPA\"])\n",
    "            data.append(row)\n",
    "    return data\n",
    "\n",
    "def discretize_cgpa(cgpa):\n",
    "    if cgpa >= 9:\n",
    "        return \"High\"\n",
    "    elif cgpa >= 8:\n",
    "        return \"Medium\"\n",
    "    else:\n",
    "        return \"Low\"\n",
    "\n",
    "def entropy(data_subset):\n",
    "    labels = [record[\"JobOffer\"] for record in data_subset]\n",
    "    total = len(labels)\n",
    "    if total == 0:\n",
    "        return 0\n",
    "    counts = Counter(labels)\n",
    "    ent = 0.0\n",
    "    for count in counts.values():\n",
    "        p = count / total\n",
    "        ent -= p * math.log2(p)\n",
    "    return ent\n",
    "\n",
    "def info_gain(data_subset, attribute):\n",
    "    total_entropy = entropy(data_subset)\n",
    "    values = set(record[attribute] for record in data_subset)\n",
    "    total = len(data_subset)\n",
    "    weighted_entropy = 0.0\n",
    "\n",
    "    for val in values:\n",
    "        subset = [record for record in data_subset if record[attribute] == val]\n",
    "        weighted_entropy += (len(subset) / total) * entropy(subset)\n",
    "\n",
    "    return total_entropy - weighted_entropy\n",
    "\n",
    "def majority_class(data_subset):\n",
    "    labels = [record[\"JobOffer\"] for record in data_subset]\n",
    "    if not labels:\n",
    "        return None\n",
    "    return Counter(labels).most_common(1)[0][0]\n",
    "\n",
    "# ---------- Iterative ID3 ----------\n",
    "\n",
    "def id3_iterative(data, attributes):\n",
    "    root = {\"attribute\": None, \"children\": {}, \"label\": None, \"data\": data, \"remaining_attrs\": attributes}\n",
    "    queue = deque([root])\n",
    "\n",
    "    while queue:\n",
    "        node = queue.popleft()\n",
    "        subset = node[\"data\"]\n",
    "        attrs = node[\"remaining_attrs\"]\n",
    "        labels = [record[\"JobOffer\"] for record in subset]\n",
    "\n",
    "        # Pure node → leaf\n",
    "        if len(set(labels)) == 1:\n",
    "            node[\"label\"] = labels[0]\n",
    "            node.pop(\"data\", None)\n",
    "            node.pop(\"remaining_attrs\", None)\n",
    "            continue\n",
    "\n",
    "        # No attributes left → majority class\n",
    "        if not attrs:\n",
    "            node[\"label\"] = majority_class(subset)\n",
    "            node.pop(\"data\", None)\n",
    "            node.pop(\"remaining_attrs\", None)\n",
    "            continue\n",
    "\n",
    "        # Pick best attribute\n",
    "        gains = [(attr, info_gain(subset, attr)) for attr in attrs]\n",
    "        best_attr, best_gain = max(gains, key=lambda x: x[1])\n",
    "\n",
    "        if best_gain == 0:\n",
    "            node[\"label\"] = majority_class(subset)\n",
    "            node.pop(\"data\", None)\n",
    "            node.pop(\"remaining_attrs\", None)\n",
    "            continue\n",
    "\n",
    "        node[\"attribute\"] = best_attr\n",
    "        node[\"children\"] = {}\n",
    "\n",
    "        values = set(record[best_attr] for record in subset)\n",
    "        for val in values:\n",
    "            child_subset = [record for record in subset if record[best_attr] == val]\n",
    "            child_node = {\n",
    "                \"attribute\": None,\n",
    "                \"children\": {},\n",
    "                \"label\": None,\n",
    "                \"data\": child_subset,\n",
    "                \"remaining_attrs\": [a for a in attrs if a != best_attr],\n",
    "            }\n",
    "            node[\"children\"][val] = child_node\n",
    "            queue.append(child_node)\n",
    "\n",
    "        # remove heavy data\n",
    "        node.pop(\"data\", None)\n",
    "        node.pop(\"remaining_attrs\", None)\n",
    "\n",
    "    return root\n",
    "\n",
    "# ---------- Prediction ----------\n",
    "\n",
    "def predict(tree, sample, default_class=None):\n",
    "    while isinstance(tree, dict):\n",
    "        if tree.get(\"label\") is not None:\n",
    "            return tree[\"label\"]\n",
    "\n",
    "        attribute = tree.get(\"attribute\")\n",
    "        if attribute is None:\n",
    "            return default_class\n",
    "\n",
    "        value = sample.get(attribute)\n",
    "        if value not in tree[\"children\"]:\n",
    "            return default_class\n",
    "        tree = tree[\"children\"][value]\n",
    "\n",
    "    return default_class\n",
    "\n",
    "# ---------- Example run ----------\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    data = load_dataset(\"job_data.csv\")\n",
    "\n",
    "    # discretize CGPA\n",
    "    for record in data:\n",
    "        record[\"CGPA\"] = discretize_cgpa(record[\"CGPA\"])\n",
    "\n",
    "    attributes = [\"CGPA\", \"Interactive\", \"Practical\", \"Communication\"]\n",
    "\n",
    "    decision_tree = id3_iterative(data, attributes)\n",
    "    print(\"Decision Tree (Iterative ID3):\")\n",
    "    pprint.pprint(decision_tree)\n",
    "\n",
    "    new_sample = {\n",
    "        \"CGPA\": discretize_cgpa(7.0),\n",
    "        \"Interactive\": \"Yes\",\n",
    "        \"Practical\": \"Good\",\n",
    "        \"Communication\": \"Moderate\"\n",
    "    }\n",
    "\n",
    "    prediction = predict(decision_tree, new_sample, default_class=majority_class(data))\n",
    "    print(f\"\\nPredicted Job Offer for {new_sample}: {prediction}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "36c9f2ab-10ee-4c53-936d-7c5953967516",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree (Iterative ID3):\n",
      "{'attribute': 'CGPA',\n",
      " 'children': {'High': {'attribute': 'Practical',\n",
      "                       'children': {'AVG': {'attribute': None,\n",
      "                                            'children': {},\n",
      "                                            'label': 'N'},\n",
      "                                    'G': {'attribute': None,\n",
      "                                          'children': {},\n",
      "                                          'label': 'Y'},\n",
      "                                    'VG': {'attribute': None,\n",
      "                                           'children': {},\n",
      "                                           'label': 'Y'}},\n",
      "                       'label': None},\n",
      "              'Low': {'attribute': None, 'children': {}, 'label': 'N'},\n",
      "              'Medium': {'attribute': None, 'children': {}, 'label': 'Y'}},\n",
      " 'label': None}\n",
      "\n",
      "Predicted Job Offer for {'CGPA': 'Medium', 'Interactive': 'Y', 'Practical': 'G', 'Communication': 'M'}: Y\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "from collections import Counter, deque\n",
    "import csv\n",
    "import pprint\n",
    "\n",
    "# ---------- Helper functions ----------\n",
    "\n",
    "def load_dataset(filename):\n",
    "    data = []\n",
    "    with open(filename, newline=\"\") as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        for row in reader:\n",
    "            # Keep CGPA as a string (>=9, >=8, <8)\n",
    "            data.append(row)\n",
    "    return data\n",
    "\n",
    "def discretize_cgpa(cgpa_str):\n",
    "    \"\"\"\n",
    "    Map your dataset's CGPA string values (>=9, >=8, <8) into categories.\n",
    "    \"\"\"\n",
    "    if cgpa_str.startswith(\">=\"):\n",
    "        value = float(cgpa_str[2:])\n",
    "        if value >= 9:\n",
    "            return \"High\"\n",
    "        elif value >= 8:\n",
    "            return \"Medium\"\n",
    "    elif cgpa_str.startswith(\"<\"):\n",
    "        return \"Low\"\n",
    "    return \"Low\"  # fallback\n",
    "\n",
    "def entropy(data_subset):\n",
    "    labels = [record[\"JobOffer\"] for record in data_subset]\n",
    "    total = len(labels)\n",
    "    if total == 0:\n",
    "        return 0\n",
    "    counts = Counter(labels)\n",
    "    ent = 0.0\n",
    "    for count in counts.values():\n",
    "        p = count / total\n",
    "        ent -= p * math.log2(p)\n",
    "    return ent\n",
    "\n",
    "def info_gain(data_subset, attribute):\n",
    "    total_entropy = entropy(data_subset)\n",
    "    values = set(record[attribute] for record in data_subset)\n",
    "    total = len(data_subset)\n",
    "    weighted_entropy = 0.0\n",
    "\n",
    "    for val in values:\n",
    "        subset = [record for record in data_subset if record[attribute] == val]\n",
    "        weighted_entropy += (len(subset) / total) * entropy(subset)\n",
    "\n",
    "    return total_entropy - weighted_entropy\n",
    "\n",
    "def majority_class(data_subset):\n",
    "    labels = [record[\"JobOffer\"] for record in data_subset]\n",
    "    if not labels:\n",
    "        return None\n",
    "    return Counter(labels).most_common(1)[0][0]\n",
    "\n",
    "# ---------- Iterative ID3 ----------\n",
    "\n",
    "def id3_iterative(data, attributes):\n",
    "    root = {\"attribute\": None, \"children\": {}, \"label\": None, \"data\": data, \"remaining_attrs\": attributes}\n",
    "    queue = deque([root])\n",
    "\n",
    "    while queue:\n",
    "        node = queue.popleft()\n",
    "        subset = node[\"data\"]\n",
    "        attrs = node[\"remaining_attrs\"]\n",
    "        labels = [record[\"JobOffer\"] for record in subset]\n",
    "\n",
    "        # Pure node → leaf\n",
    "        if len(set(labels)) == 1:\n",
    "            node[\"label\"] = labels[0]\n",
    "            node.pop(\"data\", None)\n",
    "            node.pop(\"remaining_attrs\", None)\n",
    "            continue\n",
    "\n",
    "        # No attributes left → majority class\n",
    "        if not attrs:\n",
    "            node[\"label\"] = majority_class(subset)\n",
    "            node.pop(\"data\", None)\n",
    "            node.pop(\"remaining_attrs\", None)\n",
    "            continue\n",
    "\n",
    "        # Pick best attribute\n",
    "        gains = [(attr, info_gain(subset, attr)) for attr in attrs]\n",
    "        best_attr, best_gain = max(gains, key=lambda x: x[1])\n",
    "\n",
    "        if best_gain == 0:\n",
    "            node[\"label\"] = majority_class(subset)\n",
    "            node.pop(\"data\", None)\n",
    "            node.pop(\"remaining_attrs\", None)\n",
    "            continue\n",
    "\n",
    "        node[\"attribute\"] = best_attr\n",
    "        node[\"children\"] = {}\n",
    "\n",
    "        values = set(record[best_attr] for record in subset)\n",
    "        for val in values:\n",
    "            child_subset = [record for record in subset if record[best_attr] == val]\n",
    "            child_node = {\n",
    "                \"attribute\": None,\n",
    "                \"children\": {},\n",
    "                \"label\": None,\n",
    "                \"data\": child_subset,\n",
    "                \"remaining_attrs\": [a for a in attrs if a != best_attr],\n",
    "            }\n",
    "            node[\"children\"][val] = child_node\n",
    "            queue.append(child_node)\n",
    "\n",
    "        # remove heavy data\n",
    "        node.pop(\"data\", None)\n",
    "        node.pop(\"remaining_attrs\", None)\n",
    "\n",
    "    return root\n",
    "\n",
    "# ---------- Prediction ----------\n",
    "\n",
    "def predict(tree, sample, default_class=None):\n",
    "    while isinstance(tree, dict):\n",
    "        if tree.get(\"label\") is not None:\n",
    "            return tree[\"label\"]\n",
    "\n",
    "        attribute = tree.get(\"attribute\")\n",
    "        if attribute is None:\n",
    "            return default_class\n",
    "\n",
    "        value = sample.get(attribute)\n",
    "        if value not in tree[\"children\"]:\n",
    "            return default_class\n",
    "        tree = tree[\"children\"][value]\n",
    "\n",
    "    return default_class\n",
    "\n",
    "# ---------- Example run ----------\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    data = load_dataset(\"job_data.csv\")\n",
    "\n",
    "    # discretize CGPA strings into categories\n",
    "    for record in data:\n",
    "        record[\"CGPA\"] = discretize_cgpa(record[\"CGPA\"])\n",
    "\n",
    "    attributes = [\"CGPA\", \"Interactive\", \"Practical\", \"Communication\"]\n",
    "\n",
    "    decision_tree = id3_iterative(data, attributes)\n",
    "    print(\"Decision Tree (Iterative ID3):\")\n",
    "    pprint.pprint(decision_tree)\n",
    "\n",
    "    new_sample = {\n",
    "        \"CGPA\": discretize_cgpa(\">=8\"),\n",
    "        \"Interactive\": \"Y\",\n",
    "        \"Practical\": \"G\",\n",
    "        \"Communication\": \"M\"\n",
    "    }\n",
    "\n",
    "    prediction = predict(decision_tree, new_sample, default_class=majority_class(data))\n",
    "    print(f\"\\nPredicted Job Offer for {new_sample}: {prediction}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e8d7030-1f3b-44dc-a4e7-a0d4fe6d0cda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree (Iterative ID3):\n",
      "{'CGPA': {'<8': 'N',\n",
      "          '>=8': 'Y',\n",
      "          '>=9': {'Practical': {'AVG': 'N', 'G': 'Y', 'VG': 'Y'}}}}\n",
      "\n",
      "Predicted Job Offer: Y\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "from collections import Counter, deque\n",
    "import csv\n",
    "import pprint\n",
    "\n",
    "# ---------- Helper functions ----------\n",
    "def load_dataset(filename):\n",
    "    data = []\n",
    "    with open(filename, newline=\"\") as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        for row in reader:\n",
    "            # Keep CGPA as string: >=9, >=8, <8\n",
    "            data.append(row)\n",
    "    return data\n",
    "\n",
    "def entropy(data_subset):\n",
    "    labels = [record[\"JobOffer\"] for record in data_subset]\n",
    "    total = len(labels)\n",
    "    if total == 0:\n",
    "        return 0\n",
    "    counts = Counter(labels)\n",
    "    ent = 0.0\n",
    "    for count in counts.values():\n",
    "        p = count / total\n",
    "        ent -= p * math.log2(p)\n",
    "    return ent\n",
    "\n",
    "def info_gain(data_subset, attribute):\n",
    "    total_entropy = entropy(data_subset)\n",
    "    values = set(record[attribute] for record in data_subset)\n",
    "    total = len(data_subset)\n",
    "    weighted_entropy = 0.0\n",
    "\n",
    "    for val in values:\n",
    "        subset = [record for record in data_subset if record[attribute] == val]\n",
    "        weighted_entropy += (len(subset) / total) * entropy(subset)\n",
    "\n",
    "    return total_entropy - weighted_entropy\n",
    "\n",
    "def majority_class(data_subset):\n",
    "    labels = [record[\"JobOffer\"] for record in data_subset]\n",
    "    if not labels:\n",
    "        return None\n",
    "    return Counter(labels).most_common(1)[0][0]\n",
    "\n",
    "# ---------- Iterative ID3 ----------\n",
    "def id3_iterative(data, attributes):\n",
    "    root = {\"attribute\": None, \"children\": {}, \"label\": None, \"data\": data, \"remaining_attrs\": attributes}\n",
    "    queue = deque([root])\n",
    "\n",
    "    while queue:\n",
    "        node = queue.popleft()\n",
    "        subset = node[\"data\"]\n",
    "        attrs = node[\"remaining_attrs\"]\n",
    "        labels = [record[\"JobOffer\"] for record in subset]\n",
    "\n",
    "        # Pure node → leaf\n",
    "        if len(set(labels)) == 1:\n",
    "            node[\"label\"] = labels[0]\n",
    "            node.pop(\"data\", None)\n",
    "            node.pop(\"remaining_attrs\", None)\n",
    "            continue\n",
    "\n",
    "        # No attributes left → majority class\n",
    "        if not attrs:\n",
    "            node[\"label\"] = majority_class(subset)\n",
    "            node.pop(\"data\", None)\n",
    "            node.pop(\"remaining_attrs\", None)\n",
    "            continue\n",
    "\n",
    "        # Pick best attribute (force CGPA first if available)\n",
    "        if \"CGPA\" in attrs:\n",
    "            best_attr = \"CGPA\"\n",
    "        else:\n",
    "            gains = [(attr, info_gain(subset, attr)) for attr in attrs]\n",
    "            best_attr, best_gain = max(gains, key=lambda x: x[1])\n",
    "\n",
    "        node[\"attribute\"] = best_attr\n",
    "        node[\"children\"] = {}\n",
    "\n",
    "        values = set(record[best_attr] for record in subset)\n",
    "        for val in values:\n",
    "            child_subset = [record for record in subset if record[best_attr] == val]\n",
    "            child_node = {\n",
    "                \"attribute\": None,\n",
    "                \"children\": {},\n",
    "                \"label\": None,\n",
    "                \"data\": child_subset,\n",
    "                \"remaining_attrs\": [a for a in attrs if a != best_attr],\n",
    "            }\n",
    "            node[\"children\"][val] = child_node\n",
    "            queue.append(child_node)\n",
    "\n",
    "        # cleanup\n",
    "        node.pop(\"data\", None)\n",
    "        node.pop(\"remaining_attrs\", None)\n",
    "\n",
    "    return root\n",
    "\n",
    "# ---------- Prediction ----------\n",
    "def predict(tree, sample, default_class=None):\n",
    "    while isinstance(tree, dict):\n",
    "        if tree.get(\"label\") is not None:\n",
    "            return tree[\"label\"]\n",
    "\n",
    "        attribute = tree.get(\"attribute\")\n",
    "        if attribute is None:\n",
    "            return default_class\n",
    "\n",
    "        value = sample.get(attribute)\n",
    "        if value not in tree[\"children\"]:\n",
    "            return default_class\n",
    "        tree = tree[\"children\"][value]\n",
    "\n",
    "    return default_class\n",
    "def simplify_tree(node):\n",
    "    \"\"\"Convert verbose ID3 tree into clean dict format like C4.5.\"\"\"\n",
    "    if node.get(\"label\") is not None:\n",
    "        return node[\"label\"]\n",
    "\n",
    "    attr = node.get(\"attribute\")\n",
    "    if attr is None:\n",
    "        return None\n",
    "\n",
    "    simplified = {attr: {}}\n",
    "    for val, child in node[\"children\"].items():\n",
    "        simplified[attr][val] = simplify_tree(child)\n",
    "    return simplified\n",
    "\n",
    "# ---------- Example run ----------\n",
    "if __name__ == \"__main__\":\n",
    "    data = load_dataset(\"job_data.csv\")\n",
    "\n",
    "    # keep CGPA as original strings\n",
    "    attributes = [\"CGPA\", \"Interactive\", \"Practical\", \"Communication\"]\n",
    "\n",
    "    decision_tree = id3_iterative(data, attributes)\n",
    "    simple_tree = simplify_tree(decision_tree)\n",
    "\n",
    "    print(\"Decision Tree (Iterative ID3):\")\n",
    "    pprint.pprint(simple_tree)\n",
    "\n",
    "    new_sample = {\n",
    "        \"CGPA\": \">=8\",\n",
    "        \"Interactive\": \"Y\",\n",
    "        \"Practical\": \"G\",\n",
    "        \"Communication\": \"M\"\n",
    "    }\n",
    "\n",
    "    prediction = predict(decision_tree, new_sample, default_class=majority_class(data))\n",
    "    print(f\"\\nPredicted Job Offer: {prediction}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66856aad-b244-4e5b-aee1-ef245f2bd719",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
